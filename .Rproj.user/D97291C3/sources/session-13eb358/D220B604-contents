#### SETUP ####
# libraries 
library(tigris)
library(yelpr)
library(tidyverse)
library(sf)
library(mapview)
library(httr)
library(viridis)

#### phila boundaries via tigris package ####
options(tigris_use_cache = TRUE) # set cache = TRUE to save time for future calls

zcta <- zctas(year = 2021) %>% # get all ZIPs in US (we can't filter by state unfortunately)
  rename(zip_code = GEOID20) %>% 
  st_transform("EPSG:2272") %>% # re-project
  filter(substr(ZCTA5CE20, start = 1, stop = 3) == "191") %>%
  erase_water(area_threshold = 0.5)

zcta_bg <- zctas(year = 2021) %>% # get all ZIPs in US
  rename(zip_code = GEOID20) %>% 
  st_transform("EPSG:2272") %>% # re-project
  st_crop(st_bbox(zcta %>% st_buffer(5000))) %>%
  erase_water(area_threshold = 0.5)


zip_list <- zcta$ZCTA5CE20 # list of zip codes to include in API query

phl_bound <- st_union(zcta) %>% # phl boundary
  st_as_sf()

roads_pa <- primary_secondary_roads(state = "PA", year = 2021) %>%
  st_transform("EPSG:2272") %>%
  st_crop(st_bbox(zcta %>% st_buffer(5000))) %>%
  erase_water()

roads_nj <- primary_secondary_roads(state = "NJ", year = 2021) %>%
  st_transform("EPSG:2272") %>%
  st_crop(st_bbox(zcta %>% st_buffer(5000))) %>%
  erase_water()

roads <- rbind(roads_nj, roads_pa)


#### Yelp api call function ####
url <- "https://api.yelp.com/v3/businesses/search"

get_yelp = function(category, zip_code, offset_num) { # args are category of business, zipcode, and number to offset by
  
  queryString = list(
    location = zip_code, # argument to be filled
    term = "oxtail", # argument to be filled
    sort_by = "distance", # sort by dist
    limit = 50, # 50 is the max for yelp fusion api, any higher and it won't work
    offset = offset_num # argument to be filled
  )
  
  # use "GET" verb to request information from url
  response <- VERB("GET", url, query = queryString, 
                   add_headers('Authorization' = 'Bearer RF7JfYA8GMJRVlASJCtsrJvLMhE8nbKDjkQ8B_7ZYUPWforzJV1mNDb6ibRWJfMUu_RHFG-NxCF1QHeasyOxlpid7ZbQ1tQBcACDZBWE2rLYKDhWD8Kxps0SZJJCZXYx'), 
                   content_type("application/octet-stream"), 
                   accept("application/json"))
  
  # turn the response into a json file
  yelp.json = content(response, "parsed", flatten = TRUE, simplify = TRUE)
  
  # retrieve columns from json structure
  resto.name = data.frame(yelp.json$businesses$name)
  resto.lat = data.frame(yelp.json$businesses$coordinates.latitude)
  resto.lon = data.frame(yelp.json$businesses$coordinates.longitude)
  resto.rating = data.frame(yelp.json$businesses$rating)
  resto.addr = data.frame(yelp.json$businesses$location.address1)
  
  # bind the columns into one dataframe
  yelp.df = cbind(resto.name, resto.rating, resto.addr, resto.lat, resto.lon)  %>%
    as.data.frame()
  
  colnames(yelp.df) <- c("name", "rating", "address", "lat", "lon")
  
  # add in category alias/title (this will give us cuisine information)
  cuisine = yelp.json$businesses$categories
  
  cuis.df <- map_dfr(cuisine, function(x) {
    tibble(
      alias = paste(x$alias, collapse = ", "),
      title = paste(x$title, collapse = ", ")) %>%
      as.data.frame()
  })
  
  yelp.df <- yelp.df %>%
    cbind(cuis.df)
  
  # Replace NA values with ""
  yelp.df <- yelp.df %>% 
    mutate(across(everything(), ~replace_na(.x, "")))
  
  # When creating an empty dataframe, use "" as default value
  if(nrow(yelp.df) == 0) {
    yelp.df <- data.frame(name="", rating=numeric(0), address="", lat=numeric(0), lon=numeric(0), alias = "", title = "", stringsAsFactors=FALSE)
  }
  
  return(yelp.df)
}


#### Get restaurants from yelp ####

# Initialize a named list of empty dataframes
initialize_named_dfs <- function(zips) { 
  empty_df <- data.frame(name=character(0), rating=numeric(0),  address=character(0), lat=numeric(0), lon=numeric(0))
  named_list <- lapply(zips, function(zip) empty_df)
  names(named_list) <- zips
  return(named_list)
}

resto_list_0 <- initialize_named_dfs(zip_list) # Initiate list of restaurant dataframes for each offset (since the query limit is 50, offset = 1 would return 51-100)
resto_list_1 <- initialize_named_dfs(zip_list) # 10 dfs x 50 restaurants each = a 500 restaurant sample per zip code
resto_list_2 <- initialize_named_dfs(zip_list)
resto_list_3 <- initialize_named_dfs(zip_list)

resto_list_4 <- initialize_named_dfs(zip_list)
resto_list_5 <- initialize_named_dfs(zip_list)
resto_list_6 <- initialize_named_dfs(zip_list)

resto_list_7 <- initialize_named_dfs(zip_list)
resto_list_8 <- initialize_named_dfs(zip_list)



# master list to store the dataframes
offset_list <- list(resto_list_0, resto_list_1, resto_list_2, resto_list_3,
                    resto_list_4, resto_list_5, resto_list_6, resto_list_7,
                    resto_list_8)

# Loop through each offset (think of each offset as a page of results)
for (i in 1:length(zip_list)) {
  
  # initialize zipnum (this is so we know where we're at in the list of zips)
  zipnum <- 1
  # initialize offset (so we can pull page 1, then page 2, then page 3, etc)
  offset <- i-1
  
  # Loop through each zip code
  for (zip_code in zip_list) {
    print(paste("batch ", offset + 1, ", ", "zip", zipnum, ": ", zip_code, sep = ""))
    
    # Fetch Yelp data for the zip code and store it in the list
    offset_list[[i]][[as.character(zip_code)]] <- get_yelp("restaurant", as.character(zip_code), offset)
    
    zipnum <- zipnum + 1 #iterate zipnum each loop
  }
  offset <- offset + 50
}


#### Bind dataframe ####

# Combine all dataframes into one dataframe and remove duplicates
resto.sf <- map_dfr(offset_list, ~ bind_rows(.x)) %>%
  unique() %>%
  st_as_sf(crs = 4326, coords = c("lon", "lat")) %>% 
  st_transform("EPSG:2272")

resto.sf <- resto.sf %>%
  filter(!grepl("american|Chinese|hotpot|korean|pho|vietnamese|asian|noodles|steakhouse|indian|sushi|taiwanese|shanghainese|italian|dimsum|british|cambodian", alias, ignore.case = TRUE))

phl_hex <- phl_bound %>%
  st_make_grid(cellsize = 4000, square = FALSE) %>%
  st_intersection(phl_bound) %>%
  as.data.frame() %>%
  st_as_sf() %>%
  mutate(uniqueID = row_number()) %>%
  st_transform("EPSG:2272")

resto_hex <- phl_hex %>%
  st_intersection(resto.sf) %>%
  mutate(count = 1) %>%
  group_by(uniqueID) %>%
  summarize(count = sum(count)) %>%
  ungroup() %>%
  st_drop_geometry() %>%
  full_join(phl_hex, by = "uniqueID") %>%
  mutate(count = ifelse(is.na(count) == TRUE, 0, count)) %>%
  unique() %>%
  st_as_sf()

#### VISUALS ####
# blue background rectangle for water features
water_rect <- st_as_sfc(st_bbox(zcta %>% st_buffer(5000)), crs = "EPSG:2272")

# map
ggplot() + 
  geom_sf(data = water_rect, fill = "lightblue4") +
  geom_sf(data = zcta_bg, fill = "gray10", color = "gray15", size = 0.3) +
  geom_sf(data = roads, color = "gray20", alpha = 0.3) +
  geom_sf(data = resto_hex %>% filter(count == 0), aes(fill = count), color = "transparent", alpha = 0.3) +
  geom_sf(data = resto_hex %>% filter(count > 0), aes(fill = count), color = "gray20", alpha = 0.6) +
  scale_fill_viridis(option = "C", name = "Restaurants",
                     guide = "colorbar") +
  theme_void() + theme(legend.text = element_text(color = "beige"),
                       legend.title = element_text(color = "beige"),
                       legend.direction = "horizontal",
                       legend.position = c(0.75, 0.15))


ggplot() +
  geom_sf(data = resto_hex, aes(fill = count)) +
  scale_fill_viridis(option = "C") +
  geom_sf(data = resto.sf %>% filter(name %in% c("Jaggie's Restaurant", "Tropical Choice", "Jamaican D's"))) +
  theme_void()
#### References ####
# MIME types: https://en.wikipedia.org/wiki/Media_type
# HTTR
# yelpr package
# yelp API

